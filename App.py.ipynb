{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "408d1fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews collected: 6\n",
      "Total reviews collected: 14\n",
      "Total reviews collected: 28\n",
      "Total reviews collected: 43\n",
      "Total reviews collected: 58\n",
      "Total reviews collected: 76\n",
      "Total reviews collected: 97\n",
      "Total reviews collected: 123\n",
      "Total reviews collected: 154\n",
      "Total reviews collected: 190\n",
      "Total reviews collected: 229\n",
      "Total reviews collected: 272\n",
      "Total reviews collected: 317\n",
      "Total reviews collected: 363\n",
      "Total reviews collected: 412\n",
      "Total reviews collected: 466\n",
      "Total reviews collected: 521\n",
      "Collected 521 reviews. Stopping scraping.\n",
      "Time taken: 77.47576093673706 seconds\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def WebScrape(Driver, Business, Location):\n",
    "    \n",
    "    final_collection = [] # List to collect all reviews\n",
    "    \n",
    "    driver = webdriver.Chrome(Driver)\n",
    "    driver.get(\"https://www.google.com\")\n",
    "    \n",
    "    search_box = driver.find_element(By.NAME, \"q\") # Searching for the business name and location on Google\n",
    "    search_box.send_keys(f\"{Business} {Location} reviews\")\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(1)  \n",
    "    \n",
    "    # Waiting for the review button to be clickable\n",
    "    review_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[data-async-trigger='reviewDialog']\"))\n",
    "    )\n",
    "    \n",
    "    # getting the number of reviews\n",
    "    review_text = review_button.text\n",
    "    review_counts_str = review_text.split(\" Google reviews\")[0].replace(\",\", \"\")\n",
    "    review_counts = int(review_counts_str)\n",
    "    \n",
    "    # Click the reviews button to open the review section\n",
    "    review_button.click()\n",
    "\n",
    "    review_limit = min(review_counts, 500)  # Set review limit to 500 or less if fewer reviews are available\n",
    "    review_count = 0\n",
    "\n",
    "    # Wait for the review dialog to load\n",
    "    review_dialog = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"review-dialog-list\"))\n",
    "    )\n",
    "    \n",
    "    # Scroll and scrape reviews\n",
    "    while review_count < review_limit:\n",
    "        # Use BeautifulSoup to parse the current page content\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Find all reviews (adjust class as necessary)\n",
    "        reviews = soup.find_all(\"span\", class_=\"review-full-text\")  # Modify the class if needed\n",
    "\n",
    "        # Update the review count\n",
    "        review_count += len(reviews)\n",
    "        print(f\"Total reviews collected: {review_count}\")\n",
    "\n",
    "        # Extract and append reviews\n",
    "        for review in reviews:\n",
    "            final_collection.append(review.get_text())\n",
    "        \n",
    "        # If review limit is reached, stop scraping\n",
    "        if review_count >= review_limit:\n",
    "            print(f\"Collected {review_count} reviews. Stopping scraping.\")\n",
    "            break\n",
    "        \n",
    "        # Scroll within the review dialog to load more reviews\n",
    "        scrollable_element = driver.find_element(By.CLASS_NAME, \"review-dialog-list\")\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable_element)\n",
    "        time.sleep(1)  # Adjust delay based on page load speed\n",
    "    \n",
    "    # Close the driver after scraping is done\n",
    "    driver.quit()\n",
    "\n",
    "    # Print the time taken for scraping\n",
    "    b = time.time()\n",
    "    print(f\"Time taken: {b - a} seconds\")\n",
    "    \n",
    "    # Return the collected reviews\n",
    "    return final_collection\n",
    "\n",
    "# Example usage\n",
    "Driver = r'.\\chromedriver-win64\\chromedriver.exe'\n",
    "Business = \"Dominos Pizza\"\n",
    "Location = \"Yaba\"\n",
    "\n",
    "collection = WebScrape(Driver, Business, Location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ca78d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
